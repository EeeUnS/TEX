
1 A Tour of Computer Systems 


\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{The compilation system.}
\end{figure}

linux> gcc -o hello hello.c

컴파일 시스템을 이해해야하는 이유

\begin{enumerate}
    \item 성능 최적화
    \item 링커 에러 이해하기
    \item 보안 약점
\end{enumerate}


\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{Hardware organization
    of a typical system. CPU:
    central processing unit,
    ALU: arithmetic/logic unit,
    PC: program counter, USB:
    Universal Serial Bus.}
\end{figure}


\begin{itemize}
    \item Buses
    
    하드웨어에 돌아다니는 데이터 통로(a collection of electrical conduits) word라고 하는 고정크기의 바이트 단위로 데이터가 전송된다. 최근에는 4byte 또는 8byte 크기를 가진다.

    \item I/O Devices
    시스템과 외부로부터의 연결을 가능케하는 장치.

    \item Main Memory
    
    프로세서가 프로그램을 실행하는 동안 데이터와 프로그램을 저장하는 임시 저장장치이다. 물리적으로 DRAM(Dynamic Random Access Memorry)로 구성되어 있다.

    \item Processor(CPU)
    
    프로그램 카운터(PC)는 메인메모리의 기계어 인스트럭션을 가리키는데 이 인스트럭션 값을 읽어서 특정한 동작을 수행하고 PC값을 갱신한다. 이 동작은 메인 메모리, 레지스터 파일, ALU주위를 돈다.
    레지스터 파일은 고유의 이름을 갖는 워드 크기의 레지스터 집합이다.
\end{itemize}

추가적인것 .

캐시

메모리 계층

쓰레드 동시성

프로세스 contex switching

가상메모리

파일

네트워크


\chapter{Part I Program Structure and Execution}

\section{Representing and Manipulating Information}



메모리에 객체가 저장되는 방식

객체의 수조는 사용된 바이트의 최소 주소로 정함.
4byte크기인 int type 변수 x가 주소 0x100로 설정된다면 int &x의 값은 0x100이고 주소 0x100,1,2,0x103에 x가 저장된다.


\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{ward 0x1234567이 저장되는 방식.}
\end{figure}


\begin{itemize}
    \item little endian :  최하위 바이트를 시작주소에 차례로 저장하는 방식 (intel)
    \item big endian : 최상위 바이트를 시작주소에 차례로 저장하는 방식 (IBM Oracle)
\end{itemize}


\begin{lstlisting}[style = CStyle]
 #include <stdio.h>
 typedef unsigned char *byte_pointer;

 void show_bytes(byte_pointer start, size_t len) {
 int i;
 for (i = 0; i < len; i++)
 printf(" %.2x", start[i]);
 printf("\n");
 }

 void show_int(int x) {
 show_bytes((byte_pointer) &x, sizeof(int));
 }

 void show_float(float x) {
 show_bytes((byte_pointer) &x, sizeof(float));
 }

 void show_pointer(void *x) {
 show_bytes((byte_pointer) &x, sizeof(void *));
 }


 void test_show_bytes(int val) {
     int ival = val;
     float fval = (float) ival;
     int *pval = &ival;
     show_int(ival);
     show_float(fval);
     show_pointer(pval);
     }

\end{lstlisting}
서로 다른 컴퓨터 타입은 서로 다르고, 호환성이 없는 인스트럭션과 인코딩을 사용한다. 다른 운영체제를 실행하는 동일한 프로세서들도 각자의 코딩 관습에 차이가 잇으며, 따라서 이들은 바이너리 호환성을 갖지 못한다.

\begin{lstlisting}[style = CStyle]
void inplace_swap(int *x, int *y) {
 *y = *x ^ *y; /* Step 1 */
 *x = *x ^ *y; /* Step 2 */
 *y = *x ^ *y; /* Step 3 */
 }
\end{lstlisting}


Shift Operations in C

\begin{itemize}
    \item  논리(logical) 우측 쉬프트 : 좌측 끝을 k개의 0으로 채운다.
    \item  산출(arithmetic) 우측 쉬프트 : 좌측 끝을 k개의 1로 채운다.
\end{itemize}
\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
\end{figure}


\section{Machine-Level Representation of Programs}


linux> gcc -Og -o p p1.c p2.c


-0g 옵션 : 최적화 x

ISA (instruction set architectune)

linux> gcc -Og -S mstore.c

-S : 어셈블리 코드만 만든다 .s

linux> gcc -Og -c mstore.c

바이너리 형식 목적파일 .o  생성


linux> objdump -d mstore.o

disassembly


\subsection{x86 assembly}


\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{ward 0x1234567이 저장되는 방식.}
\end{figure}




\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{ward 0x1234567이 저장되는 방식.}
\end{figure}





3.1 A Historical Perspective 202
3.2 Program Encodings 205
3.3 Data Formats 213
3.4 Accessing Information 215
3.5 Arithmetic and Logical Operations 227
3.6 Control 236
3.7 Procedures 274
3.8 Array Allocation and Access 291
3.9 Heterogeneous Data Structures 301
3.10 Combining Control and Data in Machine-Level Programs 312
3.11 Floating-Point Code 329
3.12 Summary 345

\section{Processor Architecture}

387
4.1 The Y86-64 Instruction Set Architecture 391
4.2 Logic Design and the Hardware Control Language HCL 408
4.3 Sequential Y86-64 Implementations 420
4.4 General Principles of Pipelining 448
4.5 Pipelined Y86-64 Implementations 457
4.6 Summary 506
4.6.1 Y86-64 Simulators 508
Bibliographic Notes 509
Homework Problems 509
Solutions to Practice Problems 516

\section{Optimizing Program Performance}

5.1 Capabilities and Limitations of Optimizing Compilers

\begin{enumerate}
    \item select an appropriate set of algorithms and data structures
    \item  write source code that the compiler can effectively optimize to turn into efficient executable code
    \item  divide a task into portions that can be computed in parallel, on some combination of multiple cores and multiple processors.
\end{enumerate}
명심할것. 두번째를 이해하기위해 컴파일러의 능력과 한계를 알아야한다. 최적화를 위하면서도 코드 가독성은 유지해야한다.

\subsection{Capabilities and Limitations of Optimizing Compilers}

다음 두개의 코드가 있다고 생각해보자 
\begin{lstlisting}[style = CStyle]
void twiddle1(long *xp, long *yp)
{
*xp += *yp;
*xp += *yp;
}

void twiddle2(long *xp, long *yp)
{
*xp += 2* *yp;
}
\end{lstlisting}
twiddle1은 twiddle2로 최적화 될수있는가? 답은 아니 다. xp와 yp가 동일하다고 생각해보자. 그러면 명확할 것이다.


\begin{lstlisting}[style = CStyle]
long f();
long func1() {
return f() + f() + f() + f();
}

long func2() {
return 4*f();
}
\end{lstlisting}
func1 이 func2로 최적화 될 수 있다고 생각한다. 하지만 f에서 전역변수를 건든다고 생각해보자 4번 바뀔게 한번만 바뀌는 일이 될것이다.

컴파일러는 위험요소가 있을경우 최적화를 하지않는다.

\subsection{Eliminating Loop Inefficiencies}

\begin{lstlisting}[style = CStyle]
void combine1(vec_ptr v, data_t *dest)
 {
 long i;

 *dest = IDENT;
 for (i = 0; i < vec_length(v); i++) {
 data_t val;
 get_vec_element(v, i, &val);
 *dest = *dest OP val;
 }
 }

\end{lstlisting}

이게 어떻게 성능 개선이되는지 보자.

\begin{lstlisting}[style = CStyle]
void combine2(vec_ptr v, data_t *dest)
 {
 long i;
 long length = vec_length(v);

 *dest = IDENT;
 for (i = 0; i < length; i++) {
 data_t val;
 get_vec_element(v, i, &val);
 *dest = *dest OP val;
 }
 }
\end{lstlisting}


\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{ward 0x1234567이 저장되는 방식.}
\end{figure}



\begin{lstlisting}[style = CStyle]
/* Convert string to lowercase: slow */
void lower1(char *s)
{
    long i;

    for (i = 0; i < strlen(s); i++)
        if (s[i] >= ’A’ && s[i] <= ’Z’)
            s[i] -= (’A’ - ’a’);    
}

/* Convert string to lowercase: faster */
void lower2(char *s)
{
    long i;
    long len = strlen(s);

    for (i = 0; i < len; i++)
        if (s[i] >= ’A’ && s[i] <= ’Z’)
            s[i] -= (’A’ - ’a’);
}

/* Sample implementation of library function strlen */
/* Compute length of string */
size_t strlen(const char *s)
{
    long length = 0;
    while (*s != ’\0’) {
        s++;
        length++;
    }
    return length;
}
\end{lstlisting}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{}
\end{figure}

시간복잡도 계산으로도 충분히 알 수 있다.
문자열 길이가 변하는게 아니라면 strlen을 반복문안에 넣는 짓은 하지말자.

\subsection{Reducing Procedure Calls}

\begin{lstlisting}[style = CStyle]
void combine3(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    *dest = IDENT;
    for (i = 0; i < length; i++) {
    *dest = *dest OP data[i];
    }
}
\end{lstlisting}

대충 함수안에서 계속 함수를 쳐부르는 짓은 오버헤드와 불리는 함수안에서 처리하는 불필요한 작업으로 느려진다는 뜻.
근데 뒤에 더다룬다함

\subsection{Eliminating Unneeded Memory References}

combine3에서 내부 루프는 포인터 dest가 메모리 참조를 계속하는 식이다.
다음 방식이 조금더 효율적이다.

\begin{lstlisting}[style = CStyle]
void combine4(vec_ptr v, data_t *dest)
 {
 long i;
 long length = vec_length(v);
 data_t *data = get_vec_start(v);
 data_t acc = IDENT;

for (i = 0; i < length; i++) {
 acc = acc OP data[i];
 }
 *dest = acc;
 }
\end{lstlisting}




\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{}
\end{figure}



\subsection{Understanding Modern Processors}

아몰랑


\subsection{Loop Unrolling}

while의 작동방식을 어셈블리로 한번보면 
if와  goto를 합쳐놓은 방식이다.
if는 단일 연산에비해느림 따라서
if검사를 적게 하게하면(=반복되는 횟수를 줄이면) 성능개선이 이루어진다.

\begin{lstlisting}[style = CStyle]
/* 2 x 1 loop unrolling */
void combine5(vec_ptr v, data_t *dest)
    {
    long i;
    long length = vec_length(v);
    long limit = length-1;
    data_t *data = get_vec_start(v);
    data_t acc = IDENT;

    /* Combine 2 elements at a time */
    for (i = 0; i < limit; i+=2) {
    acc = (acc OP data[i]) OP data[i+1];
    }

    /* Finish any remaining elements */
    for (; i < length; i++) {
    acc = acc OP data[i];
    }
    *dest = acc;
}
\end{lstlisting}


\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{}
\end{figure}


\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{ kx1}
\end{figure}


이 생각을 할수있다.
루프풀기를 최대로하면 제일 좋은게아닌가?

여러단점이있다.

\url{http://z3moon.com/프로그래밍/loop_unrolling}

\url{https://en.wikipedia.org/wiki/Loop_unrolling}

\begin{enumerate}
    \item 코드 크기 증가
    \item 가독성 저해
    \item 함수호출이 있을 경우 캐시 미스율 향상
\end{enumerate}

연산이 복잡해질수록 인덱스의 계산과 if조건이 수행시간에 영향을 주지않는다.
for문 내부가 간단한 코드일때 가장 효과가 좋다.

\subsection{Enhancing Parallelism}

\subsubsection{Multiple Accumulators}
연산을 나눠서 계산하고 마지막에 합치는 방식

\begin{lstlisting}[style = CStyle]
/* 2 x 2 loop unrolling */
void combine6(vec_ptr v, data_t *dest)
{
    long i;
    long length = vec_length(v);
    long limit = length-1;
    data_t *data = get_vec_start(v);
    data_t acc0 = IDENT;
    data_t acc1 = IDENT;

    /* Combine 2 elements at a time */
    for (i = 0; i < limit; i+=2) {
    acc0 = acc0 OP data[i];
    acc1 = acc1 OP data[i+1];
    }

    /* Finish any remaining elements */
    for (; i < length; i++) {
    acc0 = acc0 OP data[i];
    }
    *dest = acc0 OP acc1;
}
\end{lstlisting}

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{}
\end{figure}



\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{kxk}
\end{figure}


\subsubsection{Reassociation Transformation}


\begin{lstlisting}[style = CStyle]
/* 2 x 1a loop unrolling */
void combine7(vec_ptr v, data_t *dest)
{
long i;
long length = vec_length(v);
long limit = length-1;
data_t *data = get_vec_start(v);
data_t acc = IDENT;

/* Combine 2 elements at a time */
for (i = 0; i < limit; i+=2) {
acc = acc OP (data[i] OP data[i+1]);
}

/* Finish any remaining elements */
for (; i < length; i++) {
acc = acc OP data[i];
}
*dest = acc;
}
\end{lstlisting}

combine5의 다음코드를


\begin{lstlisting}[style = CStyle]
    acc = (acc OP data[i]) OP data[i+1];
\end{lstlisting}


\begin{lstlisting}[style = CStyle]
    acc = acc OP (data[i] OP data[i+1]);
\end{lstlisting}
로 바꾼다.

\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{}
\end{figure}


5.10 Summary of Results for Optimizing Combining Code 583
5.11 Some Limiting Factors 584
5.12 Understanding Memory Performance 589
5.13 Life in the Real World: Performance Improvement Techniques 597
5.14 Identifying and Eliminating Performance Bottlenecks 598
5.15 Summary 604


\begin{figure}[h!]
    \centering
    \includegraphics[scale=0.5]{}
    \caption{}
\end{figure}

\begin{lstlisting}[style = CStyle]
\end{lstlisting}

\begin{lstlisting}[style = CStyle]
\end{lstlisting}

\begin{lstlisting}[style = CStyle]
\end{lstlisting}

\begin{lstlisting}[style = CStyle]
\end{lstlisting}

\begin{lstlisting}[style = CStyle]
\end{lstlisting}

\begin{lstlisting}[style = CStyle]
\end{lstlisting}


6
The Memory Hierarchy 615
6.1 Storage Technologies 617
6.2 Locality 640
6.3 The Memory Hierarchy 645
6.4 Cache Memories 650
6.5 Writing Cache-Friendly Code 669
6.6 Putting It Together: The Impact of Caches on Program Performance 675
6.7 Summary 684
Bibliographic Notes 684
Homework Problems 685
Solutions to Practice Problems 696



\chapter{Part II Running Programs on a System}

\section{Linking}

7.1 Compiler Drivers 707
7.2 Static Linking 708
7.3 Object Files 709
7.4 Relocatable Object Files 710
7.5 Symbols and Symbol Tables 711
7.6 Symbol Resolution 715
7.7 Relocation 725
7.8 Executable Object Files 731
7.9 Loading Executable Object Files 733
7.10 Dynamic Linking with Shared Libraries 734
7.11 Loading and Linking Shared Libraries from Applications 737
7.12 Position-Independent Code (PIC) 740
7.13 Library Interpositioning 743
7.14 Tools for Manipulating Object Files 749
7.15 Summary 749
Bibliographic Notes 750
Homework Problems 750
Solutions to Practice Problems 753


Linker

7.1 .c-> .i -> .s -> .o ->(linker) exe

​

​

7.2 static linker

​

순서

1.symbol resolution(7.6)

2. Relocation(7.7)

​

7.3 object file(object module)

1. Relocatable ob~(7.4)

2.Executable ob~(7.8,7.9)

3.shared ob~ (7.10)

​

7.5 symbol & symbol table(.symtab section)

​

1. 전역(definition)

2. 전역(Reference)

3. 지역(locale),static -> table X

​

​

​

7.6 symbol resolution

​

1.section,symbol def Relocation

2.in section symbol ref ''

​

​

7.7 Relocation

​

-o ,-o-> .a

규칙 : 중복 symbol 처리

1. 복수의 강한 symbol(초기화된 전역) -> compiler error

2. 강 > 약(초기화 X 전역)

3. 약s->아무거나

+ static lib

​

7.8,7.9 Executable ob~

​

​

7.10,7.11

DLL, .so 














--------------------------------------------------
8
\section{Exceptional Control Flow}
8.1 Exceptions 759
8.1.1 Exception Handling 760
8.1.2 Classes of Exceptions 762
8.1.3 Exceptions in Linux/x86-64 Systems 765
8.2 Processes 768
8.2.1 Logical Control Flow 768
8.2.2 Concurrent Flows 769
8.2.3 Private Address Space 770
8.2.4 User and Kernel Modes 770
8.2.5 Context Switches 772
8.3 System Call Error Handling 773
8.4 Process Control 774
8.4.1 Obtaining Process IDs 775
8.4.2 Creating and Terminating Processes 775
8.4.3 Reaping Child Processes 779
8.4.4 Putting Processes to Sleep 785
8.4.5 Loading and Running Programs 786
8.4.6 Using fork and execve to Run Programs 789
8.5 Signals 792
8.5.1 Signal Terminology 794
8.5.2 Sending Signals 795
8.5.3 Receiving Signals 798
8.5.4 Blocking and Unblocking Signals 800
8.5.5 Writing Signal Handlers 802
8.5.6 Synchronizing Flows to Avoid Nasty Concurrency Bugs 812
8.5.7 Explicitly Waiting for Signals 814
8.6 Nonlocal Jumps 817
8.7 Tools for Manipulating Processes 822
8.8 Summary 823
Bibliographic Notes 823
Homework Problems 824
Solutions to Practice Problems 831


\section{Virtual Memory}

9.1 Physical and Virtual Addressing 839
9.2 Address Spaces 840
9.3 VM as a Tool for Caching 841
9.3.1 DRAM Cache Organization 842
9.3.2 Page Tables 842
9.3.3 Page Hits 844
9.3.4 Page Faults 844
9.3.5 Allocating Pages 846
9.3.6 Locality to the Rescue Again 846
9.4 VM as a Tool for Memory Management 847
9.5 VM as a Tool for Memory Protection 848
9.6 Address Translation 849
9.6.1 Integrating Caches and VM 853
9.6.2 Speeding Up Address Translation with a TLB 853
9.6.3 Multi-Level Page Tables 855
9.6.4 Putting It Together: End-to-End Address Translation 857
9.7 Case Study: The Intel Core i7/Linux Memory System 861
9.7.1 Core i7 Address Translation 862
9.7.2 Linux Virtual Memory System 864
9.8 Memory Mapping 869
9.8.1 Shared Objects Revisited 869
9.8.2 The fork Function Revisited 872
9.8.3 The execve Function Revisited 872
9.8.4 User-Level Memory Mapping with the mmap Function 873
9.9 Dynamic Memory Allocation 875
9.9.1 The malloc and free Functions 876
9.9.2 Why Dynamic Memory Allocation? 879
9.9.3 Allocator Requirements and Goals 880
9.9.4 Fragmentation 882
9.9.5 Implementation Issues 882
9.9.6 Implicit Free Lists 883
9.9.7 Placing Allocated Blocks 885
9.9.8 Splitting Free Blocks 885
9.9.9 Getting Additional Heap Memory 886
9.9.10 Coalescing Free Blocks 886
9.9.11 Coalescing with Boundary Tags 887
9.9.12 Putting It Together: Implementing a Simple Allocator 890
9.9.13 Explicit Free Lists 898
9.9.14 Segregated Free Lists 899
9.10 Garbage Collection 901
9.10.1 Garbage Collector Basics 902
9.10.2 Mark&Sweep Garbage Collectors 903
9.10.3 Conservative Mark&Sweep for C Programs 905
9.11 Common Memory-Related Bugs in C Programs 906
9.11.1 Dereferencing Bad Pointers 906
9.11.2 Reading Uninitialized Memory 907
9.11.3 Allowing Stack Buffer Overflows 907
9.11.4 Assuming That Pointers and the Objects They Point to
Are the Same Size 908
9.11.5 Making Off-by-One Errors 908
9.11.6 Referencing a Pointer Instead of the Object It Points To 909
9.11.7 Misunderstanding Pointer Arithmetic 909
9.11.8 Referencing Nonexistent Variables 910
9.11.9 Referencing Data in Free Heap Blocks 910
9.11.10 Introducing Memory Leaks 911
9.12 Summary 911
Bibliographic Notes 912
Homework Problems 912
Solutions to Practice Problems 916
Part III Interaction and Communication
between Programs

\section{System-Level I/O}

10.1 Unix I/O 926
10.2 Files 927
10.3 Opening and Closing Files 929
10.4 Reading and Writing Files 931
10.5 Robust Reading and Writing with the Rio Package 933
10.5.1 Rio Unbuffered Input and Output Functions 933
10.5.2 Rio Buffered Input Functions 934
10.6 Reading File Metadata 939
10.7 Reading Directory Contents 941
10.8 Sharing Files 942
10.9 I/O Redirection 945
10.10 Standard I/O 947
10.11 Putting It Together: Which I/O Functions Should I Use? 947
10.12 Summary 949
Bibliographic Notes 950
Homework Problems 950
Solutions to Practice Problems 951

\section{Network Programming}
11.1 The Client-Server Programming Model 954
11.2 Networks 955
11.3 The Global IP Internet 960
11.3.1 IP Addresses 961
11.3.2 Internet Domain Names 963
11.3.3 Internet Connections 965
11.4 The Sockets Interface 968
11.4.1 Socket Address Structures 969
11.4.2 The socket Function 970
11.4.3 The connect Function 970
11.4.4 The bind Function 971
11.4.5 The listen Function 971
11.4.6 The accept Function 972
11.4.7 Host and Service Conversion 973
11.4.8 Helper Functions for the Sockets Interface 978
11.4.9 Example Echo Client and Server 980
11.5 Web Servers 984
11.5.1 Web Basics 984
11.5.2 Web Content 985
11.5.3 HTTP Transactions 986
11.5.4 Serving Dynamic Content 989
11.6 Putting It Together: The Tiny Web Server 992
11.7 Summary 1000
Bibliographic Notes 1001
Homework Problems 1001
Solutions to Practice Problems 1002

\section{Concurrent Programming}
12.1 Concurrent Programming with Processes 1009
12.1.1 A Concurrent Server Based on Processes 1010
12.1.2 Pros and Cons of Processes 1011
12.2 Concurrent Programming with I/O Multiplexing 1013
12.2.1 A Concurrent Event-Driven Server Based on I/O
Multiplexing 1016
12.2.2 Pros and Cons of I/O Multiplexing 1021
12.3 Concurrent Programming with Threads 1021
12.3.1 Thread Execution Model 1022
12.3.2 Posix Threads 1023
12.3.3 Creating Threads 1024
12.3.4 Terminating Threads 1024
12.3.5 Reaping Terminated Threads 1025
12.3.6 Detaching Threads 1025
12.3.7 Initializing Threads 1026
12.3.8 A Concurrent Server Based on Threads 1027
12.4 Shared Variables in Threaded Programs 1028
12.4.1 Threads Memory Model 1029
12.4.2 Mapping Variables to Memory 1030
12.4.3 Shared Variables 1031
12.5 Synchronizing Threads with Semaphores 1031
12.5.1 Progress Graphs 1035
12.5.2 Semaphores 1037
12.5.3 Using Semaphores for Mutual Exclusion 1038
12.5.4 Using Semaphores to Schedule Shared Resources 1040
12.5.5 Putting It Together: A Concurrent Server Based on
Prethreading 1044
12.6 Using Threads for Parallelism 1049
12.7 Other Concurrency Issues 1056
12.7.1 Thread Safety 1056
12.7.2 Reentrancy 1059
12.7.3 Using Existing Library Functions in Threaded Programs 1060
12.7.4 Races 1061
12.7.5 Deadlocks 1063
12.8 Summary 1066
Bibliographic Notes 1066
Homework Problems 1067
Solutions to Practice Problems 1072
